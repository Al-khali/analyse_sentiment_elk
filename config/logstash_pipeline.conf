# /config/logstash_pipeline.conf

input {
  # Exemple d'input pour les données de MongoDB
  mongodb {
    uri => "mongodb://localhost:27017/social_media_data"
    placeholder_db_dir => "/var/lib/logstash/mongodb_placeholder"
    collection => "posts"
    batch_size => 5000
  }
}

filter {
  # Analyse de sentiment
  http {
    url => "http://localhost:5000/analyze_sentiment"
    body => '{"text":"%{message}"}'
    body_format => "json"
    target_body => "sentiment_analysis"
  }

  # Parsing de la réponse JSON de l'analyse de sentiment
  json {
    source => "sentiment_analysis"
    target => "sentiment"
  }

  # Ajout d'un timestamp
  date {
    match => ["created_time", "ISO8601"]
    target => "@timestamp"
  }
}

output {
  elasticsearch {
    hosts => ["http://localhost:9200"]
    user => "elastic"
    password => "votre_mot_de_passe_elasticsearch"
    index => "social_media_sentiment_%{+YYYY.MM.dd}"
  }
  
  # Output pour le débogage
  stdout { codec => rubydebug }
}